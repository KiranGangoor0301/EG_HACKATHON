{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RazT1TCqzqnc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4NdToZ8EKkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895cc82c-84b8-4df0-c54f-934e181def87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKt7qFjyEP6E"
      },
      "outputs": [],
      "source": [
        "def load_dataset(csv_path):\n",
        "    return pd.read_csv(csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrJraYT8ESdL"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(df['COBOL'])\n",
        "    y = df['Java']  # Adjusted to use Java column\n",
        "    return X, y, vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13brbzWQEUMz"
      },
      "outputs": [],
      "source": [
        "def train_model(X, y):\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X, y)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9RgGy1oEWbd"
      },
      "outputs": [],
      "source": [
        "def predict_java_keyword(model, vectorizer, cobol_keyword):\n",
        "    cobol_keyword_vectorized = vectorizer.transform([cobol_keyword])\n",
        "    java_keyword = model.predict(cobol_keyword_vectorized)\n",
        "    return java_keyword[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJBEMlK_EYee"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_predict(model, vectorizer, statement, df):\n",
        "    multi_word_keywords = {\n",
        "        'IS GREATER THAN': '>',\n",
        "        'IS LESSER THAN': '<',\n",
        "        'IS EQUAL TO': '==',\n",
        "        'IS GREATER THAN AND EQUAL TO': '>=',\n",
        "        'IS LESSER THAN AND EQUAL TO': '<='\n",
        "    }\n",
        "\n",
        "    tokens = word_tokenize(statement)\n",
        "\n",
        "    predicted_keywords = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        if i < len(tokens) - 2:\n",
        "            three_word_token = ' '.join(tokens[i:i+3]).upper()\n",
        "            if three_word_token in multi_word_keywords:\n",
        "                predicted_keywords.append(multi_word_keywords[three_word_token])\n",
        "                i += 3\n",
        "                continue\n",
        "\n",
        "        if i < len(tokens) - 3:\n",
        "            four_word_token = ' '.join(tokens[i:i+4]).upper()\n",
        "            if four_word_token in multi_word_keywords:\n",
        "                predicted_keywords.append(multi_word_keywords[four_word_token])\n",
        "                i += 4\n",
        "                continue\n",
        "\n",
        "        if tokens[i].upper() in df['COBOL'].str.upper().values:\n",
        "            predicted_keyword = predict_java_keyword(model, vectorizer, tokens[i].upper())  # Adjusted to predict Java keyword\n",
        "        else:\n",
        "            predicted_keyword = tokens[i]\n",
        "\n",
        "        predicted_keywords.append(predicted_keyword)\n",
        "        i += 1\n",
        "\n",
        "    return predicted_keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W8J9txCEdGA"
      },
      "outputs": [],
      "source": [
        "def format_java_code(predicted_keywords):\n",
        "    java_code_lines = []\n",
        "    indent_level = 0\n",
        "    indent_spaces = '  '\n",
        "\n",
        "    skip_next = False\n",
        "    display_text = ''\n",
        "\n",
        "    for i, keyword in enumerate(predicted_keywords):\n",
        "        if skip_next:\n",
        "            skip_next = False\n",
        "            continue\n",
        "\n",
        "        if keyword in ['if', 'else', 'while', 'for', 'class', 'public', 'private', 'protected', 'static', 'void', 'int', 'float', 'double', 'String']:\n",
        "            line = indent_spaces * indent_level + keyword\n",
        "            java_code_lines.append(line)\n",
        "            indent_level += 1\n",
        "        elif keyword in ['endif', 'endperform', 'endread', 'endwrite']:\n",
        "            indent_level -= 1\n",
        "            line = indent_spaces * indent_level + '}'\n",
        "            java_code_lines.append(line)\n",
        "        elif keyword == '{':\n",
        "            java_code_lines[-1] += ' {'\n",
        "            java_code_lines.append('\\n' + indent_spaces * indent_level)\n",
        "        elif keyword == '':\n",
        "            java_code_lines.append('')\n",
        "        elif keyword == 'System.out.println':\n",
        "            java_code_lines.append('\\n' + indent_spaces * indent_level + 'System.out.println(' + display_text)\n",
        "            display_text = ''\n",
        "        elif keyword.startswith('\"') and keyword.endswith('\"'):\n",
        "            display_text = keyword  # Store the quoted text for the print statement\n",
        "        else:\n",
        "            if keyword == 'THEN':\n",
        "                continue\n",
        "            if i + 1 < len(predicted_keywords) and predicted_keywords[i + 1] != '{':\n",
        "                java_code_lines.append(indent_spaces * indent_level + keyword + ' ')\n",
        "            else:\n",
        "                java_code_lines.append(indent_spaces * indent_level + keyword + ')')\n",
        "\n",
        "    formatted_code = ''.join(java_code_lines)\n",
        "\n",
        "    return formatted_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4pH74AtEiUr",
        "outputId": "beee6722-bbbb-4cde-dc52-400969843e1a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formatted Java Code:\n",
            " \n",
            "System.out.println(`` HELLO '')\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    csv_path = '/content/cobol_to_java_mapping_java.csv'\n",
        "    df = load_dataset(csv_path)\n",
        "\n",
        "    X, y, vectorizer = preprocess_data(df)\n",
        "\n",
        "    model = train_model(X, y)\n",
        "\n",
        "    while True:\n",
        "        statement = input(\"Enter a statement to tokenize (or type 'exit' to quit): \")\n",
        "\n",
        "        if statement.lower() == 'exit':\n",
        "            print(\"Exiting the program.\")\n",
        "            break\n",
        "\n",
        "        if any(char.islower() for char in statement):\n",
        "            print(\"Error: Statement must contain only uppercase characters.\")\n",
        "            continue\n",
        "\n",
        "        predicted_keywords = tokenize_and_predict(model, vectorizer, statement, df)\n",
        "\n",
        "        java_code = format_java_code(predicted_keywords)\n",
        "\n",
        "        print(\"Formatted Java Code:\\n\", java_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03bXyHr5EnDg"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_-Or1uCwSiY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q8ZYLhs5f1Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "93rHgEmpc6j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yxPR1hCZ4IRo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}